Human emotion detection is implemented in many areas requiring additional security or information about the person. 
It can be seen as a second step to face detection where we may be required to set up a second layer of security, where along with the face, the emotion is also detected. 
This can be useful to verify that the person standing in front of the camera is not just a 2-dimensional representation. Another important domain where we see the importance 
of emotion detection is for business promotions. Most of the businesses thrive on customer responses to all their products and offers. If an artificial intelligent system can
capture and identify real time emotions based on user image or video, they can make a decision on whether the customer liked or disliked the product or offer.
We have seen that security is the main reason for identifying any person. It can be based on finger-print matching, voice recognition, passwords, retina detection etc. 
Identifying the intent of the person can also be important to avert threats. This can be helpful in vulnerable areas like airports, concerts and major public gatherings
which have seen many breaches in recent years. Human emotions can be classified as: fear, contempt, disgust, anger, surprise, sad, happy, and neutral. These emotions are very subtle.
Facial muscle contortions are very minimal and detecting these differences can be very challenging as even a small difference results in different expressions. 
Also, expressions of different or even the same people might vary for the same emotion, as emotions are hugely context dependent . While we can focus on only those areas 
of the face which display a maximum of emotions like around the mouth and eyes, how we 2 extract these gestures and categorize them is still an important question. 
Neural networks and machine learning have been used for these tasks and have obtained good results. 
